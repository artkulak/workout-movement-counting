{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import cv2\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from imutils import contours\n",
    "import shutil\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "TRAINING_PATH = 'pushes/'\n",
    "BATCH_SIZE = 16\n",
    "IMG_SHAPE = (128, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomShift(object):\n",
    "    def __init__(self, shift):\n",
    "        self.shift = shift\n",
    "        \n",
    "    @staticmethod\n",
    "    def get_params(shift):\n",
    "        \"\"\"Get parameters for ``rotate`` for a random rotation.\n",
    "        Returns:\n",
    "            sequence: params to be passed to ``rotate`` for random rotation.\n",
    "        \"\"\"\n",
    "        hshift, vshift = np.random.uniform(-shift, shift, size=2)\n",
    "\n",
    "        return hshift, vshift \n",
    "    def __call__(self, img):\n",
    "        hshift, vshift = self.get_params(self.shift)\n",
    "        \n",
    "        return img.transform(img.size, Image.AFFINE, (1,0,hshift,0,1,vshift), resample=Image.BICUBIC, fill=1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorie mapping: {0: 'down', 1: 'other', 2: 'up'}\n"
     ]
    }
   ],
   "source": [
    "# define basic image transforms for preprocessing\n",
    "transform = transforms.Compose(\n",
    "[\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.RandomHorizontalFlip(0.2),\n",
    "    RandomShift(0.2),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean = (0.5,), std = (0.5, ))\n",
    "])\n",
    "\n",
    "class Dataset(torch.utils.data.Dataset):\n",
    "    '''\n",
    "    Custom Dataset object for the CDiscount competition\n",
    "        Parameters:\n",
    "            root_dir - directory including category folders with images\n",
    "\n",
    "        Example:\n",
    "        images/\n",
    "            1000001859/\n",
    "                26_0.jpg\n",
    "                26_1.jpg\n",
    "                ...\n",
    "            1000004141/\n",
    "                ...\n",
    "            ...\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.categories = sorted(os.listdir(root_dir))\n",
    "        self.cat2idx = dict(zip(self.categories, range(len(self.categories))))\n",
    "        self.idx2cat = dict(zip(self.cat2idx.values(), self.cat2idx.keys()))\n",
    "        self.files = []\n",
    "        cat_mapping = {}\n",
    "        for (dirpath, dirnames, filenames) in os.walk(self.root_dir):\n",
    "            for f in filenames:\n",
    "                if f.endswith('.png'):\n",
    "                    o = {}\n",
    "                    o['img_path'] = dirpath + '/' + f\n",
    "                    o['category'] = self.cat2idx[dirpath[dirpath.find('/')+1:]]\n",
    "                    cat_mapping[o['category']] = dirpath.split('/')[-1]\n",
    "                    self.files.append(o)\n",
    "        self.transform = transform\n",
    "        print(f'Categorie mapping: {cat_mapping}')\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.files[idx]['img_path']\n",
    "        category = self.files[idx]['category']\n",
    "        image = cv2.imread(img_path)\n",
    "        image = cv2.resize(image, IMG_SHAPE)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            \n",
    "        return {'image': image, 'category': category}\n",
    "\n",
    "\n",
    "# create instance of data class and pytorch dataloader\n",
    "dataSet = Dataset(TRAINING_PATH, transform=transform)\n",
    "dataloader = torch.utils.data.DataLoader(dataSet, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######### Network created #########\n",
      "Architecture:\n",
      " Net(\n",
      "  (conv1): Conv2d(3, 6, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (conv3): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv4): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (dropout): Dropout(p=0.3)\n",
      "  (fc1): Linear(in_features=46656, out_features=512, bias=True)\n",
      "  (bnorm1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
      "  (bnorm2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (fc3): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (bnorm3): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (fc4): Linear(in_features=64, out_features=3, bias=True)\n",
      ")\n",
      "Started Training!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (conv1): Conv2d(3, 6, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv2d(6, 16, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (conv3): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (conv4): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (dropout): Dropout(p=0.3)\n",
       "  (fc1): Linear(in_features=46656, out_features=512, bias=True)\n",
       "  (bnorm1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
       "  (bnorm2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (fc3): Linear(in_features=128, out_features=64, bias=True)\n",
       "  (bnorm3): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (fc4): Linear(in_features=64, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from Net import Net\n",
    "\n",
    "\n",
    "net = Net()\n",
    "print('######### Network created #########')\n",
    "print('Architecture:\\n', net)\n",
    "\n",
    "### Train\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=1e-3)\n",
    "\n",
    "print('Started Training!')\n",
    "net.train()\n",
    "for epoch in range(10):\n",
    "    running_loss = 0.0\n",
    "    examples = 0\n",
    "    for i, data in enumerate(dataloader, 0):\n",
    "        # Get the inputs\n",
    "        inputs, labels = data['image'], data['category']\n",
    "        \n",
    "        # Wrap them in Variable\n",
    "        inputs, labels = Variable(inputs), Variable(labels)\n",
    "\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Print statistics\n",
    "        running_loss += loss.data\n",
    "        examples += BATCH_SIZE\n",
    "    print('[%d, %5d] loss: %.3f' % (epoch + 1, i + 1, running_loss / examples))\n",
    "\n",
    "print('Finished Training!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "'''\n",
    "From: https://stackoverflow.com/questions/4623446/how-do-you-sort-files-numerically\n",
    "'''\n",
    "def tryint(s):\n",
    "    try:\n",
    "        return int(s)\n",
    "    except:\n",
    "        return s\n",
    "\n",
    "def alphanum_key(s):\n",
    "    \"\"\" Turn a string into a list of string and number chunks.\n",
    "        \"z23a\" -> [\"z\", 23, \"a\"]\n",
    "    \"\"\"\n",
    "    return [ tryint(c) for c in re.split('([0-9]+)', s) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "net.eval()\n",
    "\n",
    "transform = transforms.Compose(\n",
    "[\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean = (0.5,), std = (0.5, ))\n",
    "])\n",
    "PATH = 'classification/IMG_8266/'\n",
    "classes = []\n",
    "for frame in sorted(os.listdir(PATH), key = alphanum_key):\n",
    "    image = cv2.imread(PATH + frame)\n",
    "    image = cv2.resize(image, IMG_SHAPE)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    x = transform(image).reshape(1, 3, 128, 128)\n",
    "    classes.append(np.argmax(net(x).detach().numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def moveCount(labels):\n",
    "    k = 0\n",
    "    t = 0\n",
    "    for i in range(1, len(labels)):\n",
    "        if labels[i-1] == 0 and labels[i] == 2:\n",
    "            k+=1\n",
    "    for i in range(2, len(labels)-1):\n",
    "        if labels[i-2] == 0 and labels[i-1] == 1 and labels[i] == 2 and labels[i+1] == 2:\n",
    "            t+=1\n",
    "    return k + t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "moveCount(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save torch model for further prediction\n",
    "torch.save(net.state_dict(), 'model.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
